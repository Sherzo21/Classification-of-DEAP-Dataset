{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7420888,"sourceType":"datasetVersion","datasetId":4317501}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sklearn-genetic-opt\n# Import necessary libraries\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom scipy.signal import welch\nfrom scipy.integrate import simps\nfrom matplotlib import pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, Lasso\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn_genetic import GAFeatureSelectionCV, ExponentialAdapter\n\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T05:35:46.157781Z","iopub.execute_input":"2024-07-02T05:35:46.158477Z","iopub.status.idle":"2024-07-02T05:36:13.066869Z","shell.execute_reply.started":"2024-07-02T05:35:46.158449Z","shell.execute_reply":"2024-07-02T05:36:13.065796Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sklearn-genetic-opt\n  Downloading sklearn_genetic_opt-0.10.1-py3-none-any.whl.metadata (10.0 kB)\nRequirement already satisfied: scikit-learn>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-genetic-opt) (1.2.2)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-genetic-opt) (1.26.4)\nRequirement already satisfied: deap>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from sklearn-genetic-opt) (1.4.1)\nRequirement already satisfied: tqdm>=4.61.1 in /opt/conda/lib/python3.10/site-packages (from sklearn-genetic-opt) (4.66.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (3.2.0)\nDownloading sklearn_genetic_opt-0.10.1-py3-none-any.whl (33 kB)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: sklearn-genetic-opt\nSuccessfully installed sklearn-genetic-opt-0.10.1\n","output_type":"stream"},{"name":"stderr","text":"2024-07-02 05:36:03.137498: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-02 05:36:03.137600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-02 05:36:03.271515: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to read data\ndef read_data(filename):\n    x = pickle._Unpickler(open(filename, 'rb'))\n    x.encoding = 'latin1'\n    data = x.load()\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:36:13.068903Z","iopub.execute_input":"2024-07-02T05:36:13.069481Z","iopub.status.idle":"2024-07-02T05:36:13.074484Z","shell.execute_reply.started":"2024-07-02T05:36:13.069449Z","shell.execute_reply":"2024-07-02T05:36:13.073410Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load data\nfiles = [f\"{i:02d}\" for i in range(1, 23)]\nlabels = []\ndata = []\nfor i in files:\n    fileph = \"/kaggle/input/deap-dataset/data_preprocessed_python/s\" + i + \".dat\"\n    d = read_data(fileph)\n    labels.append(d['labels'])\n    data.append(d['data'])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:36:44.714989Z","iopub.execute_input":"2024-07-02T05:36:44.715381Z","iopub.status.idle":"2024-07-02T05:37:20.061855Z","shell.execute_reply.started":"2024-07-02T05:36:44.715353Z","shell.execute_reply":"2024-07-02T05:37:20.060819Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Convert to numpy arrays\nlabels = np.array(labels)\ndata = np.array(data)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:37:20.063594Z","iopub.execute_input":"2024-07-02T05:37:20.064300Z","iopub.status.idle":"2024-07-02T05:37:20.981410Z","shell.execute_reply.started":"2024-07-02T05:37:20.064248Z","shell.execute_reply":"2024-07-02T05:37:20.980593Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Reshape data\nlabels = labels.reshape(880, 4)\ndata = data.reshape(880, 40, 8064)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:37:21.776945Z","iopub.execute_input":"2024-07-02T05:37:21.777762Z","iopub.status.idle":"2024-07-02T05:37:21.781901Z","shell.execute_reply.started":"2024-07-02T05:37:21.777725Z","shell.execute_reply":"2024-07-02T05:37:21.780851Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Extract EEG data\neeg_data = data[:, :32, :]\n\n# Create labels dataframe\ndf_label = pd.DataFrame({'Valence': labels[:, 0], 'Arousal': labels[:, 1]})","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:37:31.890123Z","iopub.execute_input":"2024-07-02T05:37:31.890526Z","iopub.status.idle":"2024-07-02T05:37:31.898375Z","shell.execute_reply.started":"2024-07-02T05:37:31.890495Z","shell.execute_reply":"2024-07-02T05:37:31.897428Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Describe and info\nprint(df_label.describe())\nprint(df_label.info())\n\n# Binarize labels\nlabels_valence = (labels[:, 0] > 5).astype(int)\nlabels_arousal = (labels[:, 1] > 5).astype(int)\nlabels_dominance = (labels[:, 2] > 5).astype(int)\nlabels_liking = (labels[:, 3] > 6).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:37:33.383227Z","iopub.execute_input":"2024-07-02T05:37:33.384031Z","iopub.status.idle":"2024-07-02T05:37:33.425037Z","shell.execute_reply.started":"2024-07-02T05:37:33.384003Z","shell.execute_reply":"2024-07-02T05:37:33.424125Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"          Valence     Arousal\ncount  880.000000  880.000000\nmean     5.218034    5.238898\nstd      2.093837    1.879631\nmin      1.000000    1.000000\n25%      3.650000    3.895000\n50%      5.040000    5.490000\n75%      7.040000    6.795000\nmax      9.000000    9.000000\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 880 entries, 0 to 879\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Valence  880 non-null    float64\n 1   Arousal  880 non-null    float64\ndtypes: float64(2)\nmemory usage: 13.9 KB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to compute band power\ndef bandpower(data, sf, band):\n    band = np.asarray(band)\n    low, high = band\n    nperseg = (2 / low) * sf\n    freqs, psd = welch(data, sf, nperseg=nperseg)\n    freq_res = freqs[1] - freqs[0]\n    idx_band = np.logical_and(freqs >= low, freqs <= high)\n    bp = simps(psd[idx_band], dx=freq_res)\n    return bp","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:37:34.700791Z","iopub.execute_input":"2024-07-02T05:37:34.701542Z","iopub.status.idle":"2024-07-02T05:37:34.707328Z","shell.execute_reply.started":"2024-07-02T05:37:34.701509Z","shell.execute_reply":"2024-07-02T05:37:34.706330Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Get band power\ndef get_band_power(people, channel, band):\n    bands = {\"delta\": (0.5, 4), \"theta\": (4, 8), \"alpha\": (8, 12), \"beta\": (12, 30), \"gamma\": (30, 64)}\n    return bandpower(eeg_data[people, channel], 128, bands[band])\n\neeg_band = []\nfor i in range(len(eeg_data)):\n    for j in range(len(eeg_data[0])):\n        eeg_band.extend([get_band_power(i, j, b) for b in [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]])\n\neeg_band = np.array(eeg_band).reshape((880, 160))  # 5 bands x 32 channels\nnp.save(\"eeg_band.npy\", eeg_band)\neeg_band = np.load(\"eeg_band.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:37:35.953242Z","iopub.execute_input":"2024-07-02T05:37:35.953666Z","iopub.status.idle":"2024-07-02T05:38:49.851142Z","shell.execute_reply.started":"2024-07-02T05:37:35.953637Z","shell.execute_reply":"2024-07-02T05:38:49.850169Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"labels_combined = np.vstack((labels_valence, labels_arousal)).T\nmodel_names = ['Logistic Regression', 'Random Forest', 'XGBoost', 'SVM']\nmodels_lr = LogisticRegression(),\nmodels_rf = RandomForestClassifier()\nmodels_xgb = XGBClassifier(),\nmodels_svc = SVC (kernel = 'linear')","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:38:49.852918Z","iopub.execute_input":"2024-07-02T05:38:49.853208Z","iopub.status.idle":"2024-07-02T05:38:49.859089Z","shell.execute_reply.started":"2024-07-02T05:38:49.853181Z","shell.execute_reply":"2024-07-02T05:38:49.858243Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Function to compute metrics\ndef metrics(y_test, pred):\n    accuracy = accuracy_score(y_test, pred)\n    precision = precision_score(y_test, pred, average='macro')\n    recall = recall_score(y_test, pred, average='macro')\n    f1 = f1_score(y_test, pred, average='macro')\n    return accuracy, precision, recall, f1","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:38:49.860031Z","iopub.execute_input":"2024-07-02T05:38:49.860309Z","iopub.status.idle":"2024-07-02T05:38:49.868989Z","shell.execute_reply.started":"2024-07-02T05:38:49.860276Z","shell.execute_reply":"2024-07-02T05:38:49.867952Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**without feature selection**","metadata":{}},{"cell_type":"code","source":"# Cross-validation and classification with feature selection\nresults = {name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'time': []} for name in model_names}\ncv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n  # Adjust the number of features to select\ndef ML(model):\n    print(model)\n    # for model_name, model in zip(model_names, models_rf): \n    for label_type in range(2):  # For each label (valence, arousal, dominance, liking)\n        X, y = eeg_band, labels_combined[:, label_type]\n        scaler = StandardScaler()\n        X = scaler.fit_transform(X)\n        mean_acc = []\n        mean_f1 = []\n        for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n    #         print(f\"{model_name} - Label {label_type} - Fold {i+1}\")\n            start_time = time.perf_counter()\n\n            X_train, X_test = X_selected[train_index], X_selected[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n\n            model.fit(X_train, y_train)\n            pred = model.predict(X_test)\n            accuracy, precision, recall, f1 = metrics(y_test, pred)\n            mean_acc.append(accuracy)\n            mean_f1.append(f1)\n            results[model_name]['accuracy'].append(accuracy)\n            results[model_name]['precision'].append(precision)\n            results[model_name]['recall'].append(recall)\n            results[model_name]['f1'].append(f1)\n\n            elapsed_time = time.perf_counter() - start_time\n            results[model_name]['time'].append(elapsed_time)\n#             print(f\"Time: {elapsed_time:.2f} seconds\")\n        if label_type == 0:\n            print('Valence')\n        else:\n            print('Arousal')\n        print('mean acc = ', np.mean(mean_acc))\n        print('mean f1 = ', np.mean(mean_f1))\n        print('mean time = ', np.mean(results[model_name]['time']))\n# # Display results\n# for model_name in model_names:\n#     print(f\"{model_name} Results:\")\n#     for metric in ['accuracy', 'precision', 'recall', 'f1', 'time']:\n#         values = results[model_name][metric]\n#         print(f\"{metric.capitalize()}: Mean = {np.mean(values)* 100:.2f}, Std = {np.std(values):.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:11:56.815848Z","iopub.execute_input":"2024-06-30T16:11:56.816171Z","iopub.status.idle":"2024-06-30T16:11:56.829851Z","shell.execute_reply.started":"2024-06-30T16:11:56.816140Z","shell.execute_reply":"2024-06-30T16:11:56.828934Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"ML(LogisticRegression())\nML(RandomForestClassifier())  \nML(XGBClassifier())\nML(SVC(kernel = 'linear'))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:11:56.830967Z","iopub.execute_input":"2024-06-30T16:11:56.831572Z","iopub.status.idle":"2024-06-30T16:11:56.932163Z","shell.execute_reply.started":"2024-06-30T16:11:56.831541Z","shell.execute_reply":"2024-06-30T16:11:56.931039Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"LogisticRegression()\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ML(RandomForestClassifier())  \n\u001b[1;32m      3\u001b[0m ML(XGBClassifier())\n","Cell \u001b[0;32mIn[26], line 18\u001b[0m, in \u001b[0;36mML\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y)):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#         print(f\"{model_name} - Label {label_type} - Fold {i+1}\")\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 18\u001b[0m         X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX_selected\u001b[49m[train_index], X_selected[test_index]\n\u001b[1;32m     19\u001b[0m         y_train, y_test \u001b[38;5;241m=\u001b[39m y[train_index], y[test_index]\n\u001b[1;32m     21\u001b[0m         scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n","\u001b[0;31mNameError\u001b[0m: name 'X_selected' is not defined"],"ename":"NameError","evalue":"name 'X_selected' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"**Filter-based feature selection method**\n","metadata":{}},{"cell_type":"code","source":"# Cross-validation and classification with feature selection\nresults = {name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'time': []} for name in model_names}\ncv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n  # Adjust the number of features to select\ndef ML(model, selected_features):\n    print(model)\n    print('selected_features = ', selected_features)\n    num_features_to_select = selected_features\n    # for model_name, model in zip(model_names, models_rf): \n    for label_type in range(2):  # For each label (valence, arousal, dominance, liking)\n        X, y = eeg_band, labels_combined[:, label_type]\n        selector = SelectKBest(f_classif, k=num_features_to_select)\n        X_selected = selector.fit_transform(X, y)\n        scaler = StandardScaler()\n        X_selected = scaler.fit_transform(X_selected)\n        mean_acc = []\n        mean_f1 = []\n        for i, (train_index, test_index) in enumerate(cv.split(X_selected, y)):\n    #         print(f\"{model_name} - Label {label_type} - Fold {i+1}\")\n            start_time = time.perf_counter()\n\n            X_train, X_test = X_selected[train_index], X_selected[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n\n            model.fit(X_train, y_train)\n            pred = model.predict(X_test)\n            accuracy, precision, recall, f1 = metrics(y_test, pred)\n            mean_acc.append(accuracy)\n            mean_f1.append(f1)\n            results[model_name]['accuracy'].append(accuracy)\n            results[model_name]['precision'].append(precision)\n            results[model_name]['recall'].append(recall)\n            results[model_name]['f1'].append(f1)\n\n            elapsed_time = time.perf_counter() - start_time\n            results[model_name]['time'].append(elapsed_time)\n#             print(f\"Time: {elapsed_time:.2f} seconds\")\n        if label_type == 0:\n            print('Valence')\n        else:\n            print('Arousal')\n        print('mean acc = ', np.mean(mean_acc))\n        print('mean f1 = ', np.mean(mean_f1))\n        print('mean time = ', np.mean(results[model_name]['time']))\n# # Display results\n# for model_name in model_names:\n#     print(f\"{model_name} Results:\")\n#     for metric in ['accuracy', 'precision', 'recall', 'f1', 'time']:\n#         values = results[model_name][metric]\n#         print(f\"{metric.capitalize()}: Mean = {np.mean(values)* 100:.2f}, Std = {np.std(values):.4f}\")\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-30T16:12:23.922360Z","iopub.execute_input":"2024-06-30T16:12:23.923278Z","iopub.status.idle":"2024-06-30T16:12:23.937717Z","shell.execute_reply.started":"2024-06-30T16:12:23.923245Z","shell.execute_reply":"2024-06-30T16:12:23.936720Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"ML(LogisticRegression(), 50)\nML(RandomForestClassifier(), 50)  \nML(XGBClassifier(), 50)\nML(SVC(kernel = 'linear'), 50)\nML(LogisticRegression(), 100)\nML(RandomForestClassifier(), 100)  \nML(XGBClassifier(), 100)\nML(SVC(kernel = 'linear'), 100)\nML(LogisticRegression(), 150)\nML(RandomForestClassifier(), 150)  \nML(XGBClassifier(), 150)\nML(SVC(kernel = 'linear'), 150)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:12:25.834309Z","iopub.execute_input":"2024-06-30T16:12:25.835005Z","iopub.status.idle":"2024-06-30T16:12:26.051638Z","shell.execute_reply.started":"2024-06-30T16:12:25.834975Z","shell.execute_reply":"2024-06-30T16:12:26.050585Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"LogisticRegression()\nselected_features =  50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ML(RandomForestClassifier(), \u001b[38;5;241m50\u001b[39m)  \n\u001b[1;32m      3\u001b[0m ML(XGBClassifier(), \u001b[38;5;241m50\u001b[39m)\n","Cell \u001b[0;32mIn[28], line 34\u001b[0m, in \u001b[0;36mML\u001b[0;34m(model, selected_features)\u001b[0m\n\u001b[1;32m     32\u001b[0m mean_acc\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m     33\u001b[0m mean_f1\u001b[38;5;241m.\u001b[39mappend(f1)\n\u001b[0;32m---> 34\u001b[0m results[\u001b[43mmodel_name\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m     35\u001b[0m results[model_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(precision)\n\u001b[1;32m     36\u001b[0m results[model_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(recall)\n","\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"],"ename":"NameError","evalue":"name 'model_name' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Embedded-based feature selection method**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n# Cross-validation and classification with feature selection\nresults = {name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'time': []} for name in model_names}\ncv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n\n\ndef ML(model):\n    print(model)\n    # for model_name, model in zip(model_names, models_rf): \n    for label_type in range(2):  # For each label (valence, arousal, dominance, liking)\n        X, y = eeg_band, labels_combined[:, label_type]\n        selected_features = []\n        for label_index in range(labels_combined.shape[1]):\n            y = labels_combined[:, label_index]\n            lasso = Lasso()\n            params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n            cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n            lasso_cv = GridSearchCV(lasso, param_grid=params, cv=cv)\n            lasso_cv.fit(eeg_band, y)\n            best_lasso = lasso_cv.best_estimator_\n            lasso_coef = np.abs(best_lasso.coef_)\n            selected_features.append(np.where(lasso_coef > 0.000001)[0])\n        # Combine selected features for all labels\n        selected_features = np.unique(np.concatenate(selected_features))\n        print(\"Selected Feature: {}\".format(len(selected_features)))\n        X_selected = eeg_band[:, selected_features]\n        scaler = StandardScaler()\n        X_selected = scaler.fit_transform(X_selected)\n        mean_acc = []\n        mean_f1 = []\n        for i, (train_index, test_index) in enumerate(cv.split(X_selected, y)):\n    #         print(f\"{model_name} - Label {label_type} - Fold {i+1}\")\n            start_time = time.perf_counter()\n\n            X_train, X_test = X_selected[train_index], X_selected[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n\n            model.fit(X_train, y_train)\n            pred = model.predict(X_test)\n            accuracy, precision, recall, f1 = metrics(y_test, pred)\n            mean_acc.append(accuracy)\n            mean_f1.append(f1)\n            results[model_name]['accuracy'].append(accuracy)\n            results[model_name]['precision'].append(precision)\n            results[model_name]['recall'].append(recall)\n            results[model_name]['f1'].append(f1)\n\n            elapsed_time = time.perf_counter() - start_time\n            results[model_name]['time'].append(elapsed_time)\n#             print(f\"Time: {elapsed_time:.2f} seconds\")\n        if label_type == 0:\n            print('Valence')\n        else:\n            print('Arousal')\n        print('mean acc = ', np.mean(mean_acc))\n        print('mean f1 = ', np.mean(mean_f1))\n        print('mean time = ', np.mean(results[model_name]['time']))\n# # Display results\n# for model_name in model_names:\n#     print(f\"{model_name} Results:\")\n#     for metric in ['accuracy', 'precision', 'recall', 'f1', 'time']:\n#         values = results[model_name][metric]\n#         print(f\"{metric.capitalize()}: Mean = {np.mean(values)* 100:.2f}, Std = {np.std(values):.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:11:56.937147Z","iopub.status.idle":"2024-06-30T16:11:56.937612Z","shell.execute_reply.started":"2024-06-30T16:11:56.937356Z","shell.execute_reply":"2024-06-30T16:11:56.937373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ML(LogisticRegression())\nML(RandomForestClassifier())  \nML(XGBClassifier())\nML(SVC(kernel = 'linear'))","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:11:56.939848Z","iopub.status.idle":"2024-06-30T16:11:56.940287Z","shell.execute_reply.started":"2024-06-30T16:11:56.940061Z","shell.execute_reply":"2024-06-30T16:11:56.940080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Wrapper-based feature selection method**","metadata":{}},{"cell_type":"code","source":"# Cross-validation and classification with feature selection\nresults = {name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'time': []} for name in model_names}\ncv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n\n\ndef ML(model):\n    print(model)\n    clf = SVC(kernel='linear')\n    # for model_name, model in zip(model_names, models_rf): \n    for label_type in range(2):  # For each label (valence, arousal, dominance, liking)\n        X, y = eeg_band, labels_combined[:, label_type]\n        scaler = StandardScaler()\n        X = scaler.fit_transform(X)\n        X = scaler.transform(X)\n        mutation_scheduler = ExponentialAdapter(0.8, 0.2, 0.01)\n        crossover_scheduler = ExponentialAdapter(0.2, 0.8, 0.01)\n        evolved_estimator = GAFeatureSelectionCV(\n            estimator=clf,\n            scoring=\"accuracy\",\n            population_size=30,\n            generations=20,\n            mutation_probability=mutation_scheduler,\n            crossover_probability=crossover_scheduler,\n            n_jobs=-1,\n            cv=5,\n            verbose=True\n        )\n        \n        evolved_estimator.fit(X, y)\n        reduced_X = evolved_estimator.transform(X)\n        print(f'Number of selected features for label: {reduced_X.shape[1]}')\n        scaler = StandardScaler()\n        X_selected = scaler.fit_transform(reduced_X)\n        mean_acc = []\n        mean_f1 = []\n        for i, (train_index, test_index) in enumerate(cv.split(X_selected, y)):\n    #         print(f\"{model_name} - Label {label_type} - Fold {i+1}\")\n            start_time = time.perf_counter()\n\n            X_train, X_test = X_selected[train_index], X_selected[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n\n#             scaler = StandardScaler()\n#             X_train = scaler.fit_transform(X_train)\n#             X_test = scaler.transform(X_test)\n\n            clf.fit(X_train, y_train)\n            pred = clf.predict(X_test)\n            accuracy, precision, recall, f1 = metrics(y_test, pred)\n            mean_acc.append(accuracy)\n            mean_f1.append(f1)\n            results['SVM']['accuracy'].append(accuracy)\n            results['SVM']['precision'].append(precision)\n            results['SVM']['recall'].append(recall)\n            results['SVM']['f1'].append(f1)\n\n            elapsed_time = time.perf_counter() - start_time\n            results['SVM']['time'].append(elapsed_time)\n#             print(f\"Time: {elapsed_time:.2f} seconds\")\n        if label_type == 0:\n            print('Valence')\n        else:\n            print('Arousal')\n        print('mean acc = ', np.mean(mean_acc))\n        print('mean f1 = ', np.mean(mean_f1))\n        print('mean time = ', np.mean(results['SVM']['time']))\n# # Display results\n# for model_name in model_names:\n#     print(f\"{model_name} Results:\")\n#     for metric in ['accuracy', 'precision', 'recall', 'f1', 'time']:\n#         values = results[model_name][metric]\n#         print(f\"{metric.capitalize()}: Mean = {np.mean(values)* 100:.2f}, Std = {np.std(values):.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:41:56.057414Z","iopub.execute_input":"2024-07-02T05:41:56.057788Z","iopub.status.idle":"2024-07-02T05:41:56.072896Z","shell.execute_reply.started":"2024-07-02T05:41:56.057757Z","shell.execute_reply":"2024-07-02T05:41:56.072018Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# ML(LogisticRegression())\n# ML(RandomForestClassifier())  \n# ML(XGBClassifier())\nML(SVC(kernel = 'linear'))","metadata":{"execution":{"iopub.status.busy":"2024-07-02T05:41:58.124521Z","iopub.execute_input":"2024-07-02T05:41:58.125087Z","iopub.status.idle":"2024-07-02T05:45:44.196775Z","shell.execute_reply.started":"2024-07-02T05:41:58.125056Z","shell.execute_reply":"2024-07-02T05:45:44.195786Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"SVC(kernel='linear')\ngen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n0  \t30    \t0.521439\t0.00750765 \t0.535227   \t0.511364   \n1  \t60    \t0.528523\t0.00721897 \t0.535227   \t0.519318   \n2  \t60    \t0.529621\t0.00691804 \t0.535227   \t0.519318   \n3  \t60    \t0.525871\t0.00740344 \t0.535227   \t0.511364   \n4  \t60    \t0.529962\t0.00695867 \t0.535227   \t0.519318   \n5  \t60    \t0.533409\t0.00467247 \t0.535227   \t0.519318   \n6  \t60    \t0.53072 \t0.00702639 \t0.535227   \t0.514773   \n7  \t60    \t0.533902\t0.00399168 \t0.535227   \t0.520455   \n8  \t60    \t0.53322 \t0.00527876 \t0.535227   \t0.514773   \n9  \t60    \t0.530644\t0.00721976 \t0.535227   \t0.514773   \n10 \t60    \t0.532197\t0.00610777 \t0.535227   \t0.519318   \n11 \t60    \t0.530871\t0.00814218 \t0.535227   \t0.511364   \n12 \t60    \t0.5325  \t0.00555619 \t0.535227   \t0.518182   \n13 \t60    \t0.532311\t0.00587317 \t0.535227   \t0.519318   \n14 \t60    \t0.532689\t0.00570211 \t0.535227   \t0.519318   \n15 \t60    \t0.532273\t0.00672666 \t0.535227   \t0.514773   \n16 \t60    \t0.533447\t0.00457079 \t0.535227   \t0.519318   \n17 \t60    \t0.532273\t0.00668815 \t0.535227   \t0.514773   \n18 \t60    \t0.532348\t0.00578492 \t0.535227   \t0.519318   \n19 \t60    \t0.532197\t0.00608659 \t0.535227   \t0.519318   \n20 \t60    \t0.533182\t0.00521903 \t0.535227   \t0.519318   \nNumber of selected features for label: 56\nValence\nmean acc =  0.5352272727272727\nmean f1 =  0.4809135410296757\nmean time =  0.04538881220000803\ngen\tnevals\tfitness\tfitness_std\tfitness_max\tfitness_min\n0  \t30    \t0.55678\t0.0094961  \t0.582955   \t0.543182   \n1  \t60    \t0.569735\t0.0115793  \t0.582955   \t0.552273   \n2  \t60    \t0.572045\t0.0108426  \t0.582955   \t0.551136   \n3  \t60    \t0.574735\t0.0110708  \t0.582955   \t0.55       \n4  \t60    \t0.574773\t0.0118944  \t0.582955   \t0.55       \n5  \t60    \t0.575985\t0.0102556  \t0.582955   \t0.551136   \n6  \t60    \t0.577538\t0.00881046 \t0.582955   \t0.555682   \n7  \t60    \t0.576288\t0.0100991  \t0.582955   \t0.551136   \n8  \t60    \t0.574242\t0.0114027  \t0.582955   \t0.551136   \n9  \t60    \t0.574242\t0.0103083  \t0.584091   \t0.555682   \n10 \t60    \t0.575758\t0.0100246  \t0.582955   \t0.553409   \n11 \t60    \t0.575114\t0.010029   \t0.582955   \t0.554545   \n12 \t60    \t0.57553 \t0.0104345  \t0.582955   \t0.55       \n13 \t60    \t0.575303\t0.0106315  \t0.582955   \t0.552273   \n14 \t60    \t0.578258\t0.0094153  \t0.582955   \t0.552273   \n15 \t60    \t0.578182\t0.00859139 \t0.582955   \t0.553409   \n16 \t60    \t0.578712\t0.00822554 \t0.582955   \t0.551136   \n17 \t60    \t0.581629\t0.00410858 \t0.582955   \t0.560227   \n18 \t60    \t0.579886\t0.0082528  \t0.582955   \t0.552273   \n19 \t60    \t0.581212\t0.00598964 \t0.585227   \t0.556818   \n20 \t60    \t0.581326\t0.00609613 \t0.582955   \t0.557955   \nNumber of selected features for label: 89\nArousal\nmean acc =  0.6386363636363636\nmean f1 =  0.5728243787191436\nmean time =  0.05556782070000281\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}